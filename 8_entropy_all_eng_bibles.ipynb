{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_files_path = 'output/gpt2/'\n",
    "files = os.listdir(entropy_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = [file for file in files if 'entropies.csv' in file]\n",
    "stats = [file for file in files if 'stats.csv' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_dfs = [pd.read_csv(entropy_files_path + file) for file in entropies]\n",
    "stats_dfs = [pd.read_csv(entropy_files_path + file) for file in stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(entropies_dfs) == len(stats_dfs)\n",
    "for i in range(len(entropies_dfs)):\n",
    "    entropies_dfs[i]['file'] = entropies[i].split('_')[0]\n",
    "    stats_dfs[i]['file'] = stats[i].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_df = pd.concat(entropies_dfs)\n",
    "stats_df = pd.concat(stats_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis at different levels\n",
    "\n",
    "We can run the analysis at the bible, testament, book, and chapter levels, and for each report two histograms: one for H_s, and one for H_r. At the book and chapter levels we will use only H_r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'H': 'green', 'H_r': 'blue', 'H_s': 'blue', 'D_r': 'red', 'D_s': 'red'}\n",
    "levels = {'s': ('bible', 'testament'), 'r': ('bible', 'testament', 'book', 'chapter')}\n",
    "\n",
    "for method in ('s', 'r'):\n",
    "    for level in levels[method]:\n",
    "        for col in ('H', f'H_{method}', f'D_{method}'):\n",
    "            plt.hist(entropies_df[entropies_df['level'] == 'bible'][col], color=colors[col], label=col)\n",
    "        plt.title(level)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over all texts at each level\n",
    "col_aggs = {col: ['mean', 'std'] for col in entropies_df.columns if col not in {'level', 'file'}}\n",
    "# Add one more column that is the number of texts for that level\n",
    "col_aggs[list(col_aggs.keys())[0]].append('count')\n",
    "stats = entropies_df.groupby('level').agg(col_aggs)\n",
    "\n",
    "# No _s in book and chapter levels\n",
    "for col in stats.columns:\n",
    "    if '_s' in col[0]:\n",
    "        stats.at['book', col] = 'N/A'\n",
    "        stats.at['chapter', col] = 'N/A'\n",
    "        \n",
    "# Drop verses\n",
    "stats.drop(['verse'], inplace=True)\n",
    "\n",
    "# Sort by hierarchy\n",
    "hierarchy = ['bible', 'testament', 'book', 'chapter']\n",
    "stats['hierarchy'] = stats.index.map(lambda x: hierarchy.index(x))\n",
    "stats.sort_values(by='hierarchy', inplace=True)\n",
    "stats.drop(columns=['hierarchy'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's surprising that the number of tokens varies so wildly across bibles. We can look at this in further detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(entropies_df[entropies_df['level'] == 'testament']['n_tokens'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(entropies_df[entropies_df['level'] == 'bible']['n_tokens'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most of this variation seems to be due to the old vs new testament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier analysis\n",
    "\n",
    "What are the bibles with the lowest entropy differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_df[(entropies_df['level'] == 'bible') & (entropies_df['D_r'] < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a particularly short or long bible? Judging from the distribution shown above, it is rather short, but not the shortest. This \"diaglot\" bible is a literal word-by-word translation of the Greek bible. The text is order in an odd manner and it's quite difficult to read as English. This probably means that the entropy is higher than usual (and this is consistent with the observation), which causes the small entropy difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_df[(entropies_df['level'] == 'bible') & (entropies_df['D_r'] < 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic does not have a high entropy rate, but a small unigram entropy. This is probably due to the more limited vocabulary. I can't understand very much what the case is for the Etheridge bible. The \"basic\" bible is still in English, so it should be kept, but the \"diaglot\" bible is arguably not in English. If we remove it, how does the analysis change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over all texts at each level\n",
    "col_aggs = {col: ['mean', 'std'] for col in entropies_df.columns if col not in {'level', 'file'}}\n",
    "# Add one more column that is the number of texts for that level\n",
    "col_aggs[list(col_aggs.keys())[0]].append('count')\n",
    "stats = entropies_df[entropies_df['file'] != 'eng-x-bible-diaglot'].groupby('level').agg(col_aggs)\n",
    "\n",
    "# No _s in book and chapter levels\n",
    "for col in stats.columns:\n",
    "    if '_s' in col[0]:\n",
    "        stats.at['book', col] = 'N/A'\n",
    "        stats.at['chapter', col] = 'N/A'\n",
    "        \n",
    "# Drop verses\n",
    "stats.drop(['verse'], inplace=True)\n",
    "\n",
    "# Sort by hierarchy\n",
    "hierarchy = ['bible', 'testament', 'book', 'chapter']\n",
    "stats['hierarchy'] = stats.index.map(lambda x: hierarchy.index(x))\n",
    "stats.sort_values(by='hierarchy', inplace=True)\n",
    "stats.drop(columns=['hierarchy'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the statistical uncertainties become closer to the values calculated on a single bible. Not that, while we calculated the cross-entropy between GPT-2 and the bible, the cross-entropy is expected to be higher than or equal to the entropy (Gibbs' Inequality). Thus, the entropy difference should be even **larger** than reported here, unlike presented in Montemurro & Zanette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
