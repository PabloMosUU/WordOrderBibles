{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947432fc-0449-432d-8d5d-bf320304afea",
   "metadata": {},
   "source": [
    "In this notebook we analyze in detail two bible-book combinations that show the oddest transitions in notebook 34:\n",
    "\n",
    "- (ita-x-bible-vita1997.txt, Revelation) has D_structure=0 for all word-splitting datapoints and word-pasting datapoints from 0 to 300 merges\n",
    "- (etu-x-bible.txt, John) has a gap between the 0-points\n",
    "\n",
    "Finally, we look at all bibles that have relatively large gaps at the 0-points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a7f8c-3453-4df6-a83c-4433d42ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from word_splitting import create_word_split_sets, get_output_file_dir, get_entropies, join_verses, mask_word_structure\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import data\n",
    "from compression_entropy import read_selected_verses, get_char_distribution, select_samples\n",
    "import os\n",
    "from util import make_book_plot, BOOK_ID_NAME\n",
    "from analysis import get_spearman\n",
    "from compression_entropy import get_entropies as get_pasting_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce5f91-4abe-4c06-8e0b-1e0f646db947",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIBLES_PATH = '../paralleltext/bibles/corpus/'\n",
    "ITALIAN_BIBLE = 'ita-x-bible-vita1997.txt'\n",
    "ITALIAN_BOOK = 'Revelation'\n",
    "ITALIAN_BOOK_ID = 66\n",
    "LOWERCASE = True                                        # from word_splitting.py\n",
    "TRUNCATE_BOOKS = False                                  # from word_splitting.py\n",
    "REMOVE_MISMATCHER_FILES = True                          # from word_splitting.py\n",
    "N_MERGES = 30000                                        # from my standard run configuration on HPC\n",
    "OUTPUT_PATH = 'output/KoplenigEtAl/WordSplitting/temp'  # local test path\n",
    "MISMATCHER_PATH = '../KoplenigEtAl/shortestmismatcher.jar'\n",
    "\n",
    "ETU_BIBLE = 'etu-x-bible.txt'\n",
    "ETU_BOOK = 'John'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa245ce1-12b5-4f60-b0f6-832afe959c95",
   "metadata": {},
   "source": [
    "# ita-x-bible-vita1997.txt, Revelation\n",
    "\n",
    "A quick look at the raw text does not reveal any strange features. So, I will run the program in debug mode and look at some of the calculations.\n",
    "\n",
    "My first observation looking at the output numbers is that the D_order and D_structure are never 0, albeit very close. What is very strange is that, for the splitting experiment, D_structure ~ 0 for all instances. This means NONE of the information is contained in the word structure, i.e., 'masking' the words makes no difference.\n",
    "\n",
    "I verified that indeed the entropy generated for the original and masked bibles were very close (0.02% off). My first hypothesis was that the characters in this bible were very rare, so I attempted the calculation again with the a-z, A-Z, and 0-7 characters, which were the same number in total as the characters in this book. But the calculations returned very similar numbers.\n",
    "\n",
    "More tests to be run:\n",
    "\n",
    "- try uniform weighting of characters (1.42% off), which would put D_structure=0.016\n",
    "- check if D_structure=0.016 is atypical or typical for n_splits=0 -> xuo has 0.033, so maybe yes\n",
    "- compare the length of the character set (60) to that of other bible-book combinations -> xuo has 58, which is comparable\n",
    "- compare the character distribution to that of other bible-book combinations -> the distribution for the Italian bible is rather more centered at 0, though not enough to look particularly odd\n",
    "- compare the length of the bible-book combination overall with other bible-book combinations -> the Italian book has 69686 characters. The xuo book has 88415. Again, not particularly different\n",
    "- see what typical values are for other bibles with the same language and book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f68da1-95d9-4de3-8c1c-7333beb17c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('all_entropies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59fc5b-5337-46c5-bac6-93e7cd2cb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bible, grp in df[(df['bible'].apply(lambda x: x.startswith('ita'))) & (df['bible'] != 'ita-x-bible-vita1997.txt') & (df['iter_id'] == 0) & (df['book'] == 'Revelation') & (df['experiment'] == 'splitting')].groupby('bible'):\n",
    "    assert len(grp) == 1\n",
    "    orig_masked = grp[['orig', 'masked']].values[0]\n",
    "    print(bible, f'{orig_masked[1] - orig_masked[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f2806-c5c7-431a-8fcb-619522815131",
   "metadata": {},
   "source": [
    "Meanwhile, for my bible of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035875a-8937-4e90-89a4-1ced43ef55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df[(df['bible'] == 'ita-x-bible-vita1997.txt') & (df['iter_id'] == 0) & (df['book'] == 'Revelation') & (df['experiment'] == 'splitting')]\n",
    "assert len(grp) == 1\n",
    "orig_masked = grp[['orig', 'masked']].values[0]\n",
    "print(f'{orig_masked[1] - orig_masked[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a997c94-c8d7-4fc3-9a6a-d711836e67c0",
   "metadata": {},
   "source": [
    "This value is much lower than the previous ones. So let's look at the inner details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e8bd0-6786-45c8-b1a9-87a39aafe0c1",
   "metadata": {},
   "source": [
    "### Compare the character weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bfc3f-6c7b-4260-b972-c0fd8f135fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(BIBLES_PATH, ITALIAN_BIBLE)\n",
    "selected_book_verses, char_counter = read_selected_verses(filename,\n",
    "                                                          LOWERCASE,\n",
    "                                                          [ITALIAN_BOOK_ID],\n",
    "                                                          TRUNCATE_BOOKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbd1a1-5902-48b3-a451-68fcfb1c2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_char_ctr = {}\n",
    "bib_filename = {}\n",
    "bib_sel_book_verses = {}\n",
    "other_italian_bibles = df[(df['bible'].apply(lambda x: x.startswith('ita'))) & (df['bible'] != ITALIAN_BIBLE)]['bible'].unique()\n",
    "for other_ita_bib in other_italian_bibles:\n",
    "    other_filename = os.path.join(BIBLES_PATH, other_ita_bib)\n",
    "    other_sel_book_verses, other_char_ctr = read_selected_verses(other_filename, \n",
    "                                                                 LOWERCASE, \n",
    "                                                                 [ITALIAN_BOOK_ID], \n",
    "                                                                 TRUNCATE_BOOKS)\n",
    "    bib_filename[other_ita_bib] = other_filename\n",
    "    bib_sel_book_verses[other_ita_bib] = other_sel_book_verses\n",
    "    bib_char_ctr[other_ita_bib] = other_char_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8184b-e63a-44d5-b6bb-5ad2a9931954",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_chars = [el[0] for el in char_counter.most_common(10)]\n",
    "for char_ctr in bib_char_ctr.values():\n",
    "    most_common_chars += [el[0] for el in char_ctr.most_common(10)]\n",
    "most_common_chars = list(set(most_common_chars))\n",
    "print(most_common_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e3a9b-20b7-4266-a9cd-050f9dd90ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(most_common_chars, [char_counter[ch] for ch in most_common_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae46f0-9f89-4ee9-900c-a356a50c3c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bib, char_ctr in bib_char_ctr.items():\n",
    "    print(bib)\n",
    "    plt.bar(most_common_chars, [char_ctr[ch] for ch in most_common_chars])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db227d-fc2d-463f-9096-292ee51b0fd3",
   "metadata": {},
   "source": [
    "The character distributions are roughly equivalent, so no surprises there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655046d-ad18-4a23-953f-a93c1d664130",
   "metadata": {},
   "source": [
    "### Compare the values of D_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e15e4c-a6e1-464f-9130-ba2a1f039277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bible'].apply(lambda x: x.startswith('ita'))) & (df['experiment'] == 'splitting') & (df['iter_id'] == 0) & (df['book'] == 'Revelation')][['bible', 'D_structure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ab593-7da3-40bc-b49c-fe2ecbd7e999",
   "metadata": {},
   "source": [
    "Clearly a much lower value for our bible of interest, so the question remains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfca391-b34c-4806-92ab-c52679eed5f4",
   "metadata": {},
   "source": [
    "### Compare the length of the character set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca59273-6f2c-49d6-aca8-44c0acf57bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ITALIAN_BIBLE, len(char_counter.keys()))\n",
    "for bib, char_ctr in bib_char_ctr.items():\n",
    "    print(bib, len(char_ctr.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cbb447-3519-4a15-a6de-6860cc051903",
   "metadata": {},
   "source": [
    "Nothing strange here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513cef12-284b-4e87-b7ab-7ec647a21943",
   "metadata": {},
   "source": [
    "### compare the length of the bible-book combinations overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473aa15b-3d9e-4288-a4c3-012461957013",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_sel_book_verses[ITALIAN_BIBLE] = selected_book_verses\n",
    "for bib, sel_book_verses in bib_sel_book_verses.items():\n",
    "    book_id_versions = create_word_split_sets(sel_book_verses, N_MERGES, OUTPUT_PATH, bib)\n",
    "    n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "    sample_verses = n_pairs_verses[0]\n",
    "    verse_tokens = random.sample(sample_verses, k=len(sample_verses))\n",
    "    joined_orig = join_verses(verse_tokens, insert_spaces=True)\n",
    "    print(bib, type(joined_orig), len(joined_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470a3b1-ba50-4c5d-90af-fabe9a0c57ee",
   "metadata": {},
   "source": [
    "Rather normal in this way too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470fba8-7963-48a8-81ee-24fcd0bad5e0",
   "metadata": {},
   "source": [
    "## Further verifications\n",
    "\n",
    "- Reproducir el resultado\n",
    "- Chequear que las palabras estén reemplazadas\n",
    "- Mirar las biblias a ojo\n",
    "- Espacios\n",
    "- Hacer el masking con seeds diferentes y ver si cambia la cantidad\n",
    "- Indices de los versículos\n",
    "- Repeticion de texto\n",
    "- Commits más recientes en esta Biblia\n",
    "- Hacer el análisis sólo con la mitad del libro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2666c2-cfa5-4ee9-a64c-5f986319901e",
   "metadata": {},
   "source": [
    "### Reproducir el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69543897-c96c-4e45-87d0-9d93bcef0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bible'].apply(lambda x: x.startswith('ita'))) & (df['book'] == 'Revelation') & (df['iter_id'] == 0) & (df['experiment'] == 'splitting')][['bible', 'D_structure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb925fa-e2a9-4b97-9a9f-3fe3c79b113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_versions = create_word_split_sets(bib_sel_book_verses[ITALIAN_BIBLE], \n",
    "                                          N_MERGES, \n",
    "                                          OUTPUT_PATH, \n",
    "                                          ITALIAN_BIBLE)\n",
    "n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "verse_tokens = n_pairs_verses[0]\n",
    "filename = os.path.join(BIBLES_PATH, ITALIAN_BIBLE)\n",
    "base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{ITALIAN_BOOK_ID}_v{0}')\n",
    "entropies = get_entropies(verse_tokens,\n",
    "                                                       base_filename,\n",
    "                                                       REMOVE_MISMATCHER_FILES,\n",
    "                                                       char_counter,\n",
    "                                                       MISMATCHER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bed807-8cb4-45da-bc75-ff06d0b2504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropies)\n",
    "print(entropies['masked'] - entropies['orig'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36e76d-7226-432c-be56-9e13b8374578",
   "metadata": {},
   "source": [
    "This is the same as before. What about another Italian bible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed3e3c-a618-4a88-89cb-1abe467b0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_versions = create_word_split_sets(bib_sel_book_verses['ita-x-bible-riveduta.txt'], \n",
    "                                          N_MERGES, \n",
    "                                          OUTPUT_PATH, \n",
    "                                          'ita-x-bible-riveduta.txt')\n",
    "n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "verse_tokens = n_pairs_verses[0]\n",
    "filename = os.path.join(BIBLES_PATH, 'ita-x-bible-riveduta.txt')\n",
    "base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{ITALIAN_BOOK_ID}_v{0}')\n",
    "entropies = get_entropies(verse_tokens,\n",
    "                                                       base_filename,\n",
    "                                                       REMOVE_MISMATCHER_FILES,\n",
    "                                                       bib_char_ctr['ita-x-bible-riveduta.txt'],\n",
    "                                                       MISMATCHER_PATH)\n",
    "print(entropies)\n",
    "print(entropies['masked'] - entropies['orig'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c839da5-16fc-4374-aea7-ada0aeb425d4",
   "metadata": {},
   "source": [
    "Also similar to the value saved in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe4652-e5c9-4a60-9576-a6f357f1493e",
   "metadata": {},
   "source": [
    "### Chequear que las palabras estén reemplazadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432c454-7279-4565-b11e-415749ee3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_versions = create_word_split_sets(bib_sel_book_verses[ITALIAN_BIBLE], \n",
    "                                          N_MERGES, OUTPUT_PATH, ITALIAN_BIBLE)\n",
    "n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "sample_verses = n_pairs_verses[0]\n",
    "# Randomize the order of the verses in each sample\n",
    "verse_tokens = random.sample(sample_verses, k=len(sample_verses))\n",
    "# Mask word structure\n",
    "char_str = ''.join(char_counter.keys())\n",
    "char_weights = [char_counter[el] for el in char_str]\n",
    "masked = mask_word_structure(verse_tokens, char_str, char_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821882fe-61d8-4d60-8fd8-75eb18944bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838f1a0-55a1-429d-9cbb-220e2ad2c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([el.token for el in masked[sample_index][:30]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251a868-a922-42a9-82b8-b814f9c61d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([el.token for el in verse_tokens[sample_index][:30]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397761d4-94a4-48a9-b5d0-191c308af30f",
   "metadata": {},
   "source": [
    "The replacement seems to be working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e6355-770f-4204-85d2-c06d2f98972f",
   "metadata": {},
   "source": [
    "### Mirar las biblias a ojo\n",
    "\n",
    "Voy a comparar con una de las otras biblias en italiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a2673-a08b-4028-9fe3-70c6677676f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BIBLES_PATH, ITALIAN_BIBLE)) as f:\n",
    "    bad_lines = f.readlines()\n",
    "with open(os.path.join(BIBLES_PATH, other_italian_bibles[0])) as f:\n",
    "    good_lines = f.readlines()\n",
    "print('comparing', ITALIAN_BIBLE, 'and', other_italian_bibles[0])\n",
    "bad_rev = [el for el in bad_lines if el.strip().startswith('66')]\n",
    "good_rev = [el for el in good_lines if el.strip().startswith('66')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f23c8-0f8c-4928-85c2-96b74b39d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bad_rev), len(good_rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ad3fd-8b70-49cc-993b-0a14158f46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = random.randint(0, len(bad_rev) + 2)\n",
    "print(bad_rev[sample_index])\n",
    "print(good_rev[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446bda7-4530-4c7e-a888-fb4c54e094a1",
   "metadata": {},
   "source": [
    "No veo diferencias significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a32113-04c0-41a8-9356-a9dde4adb9d3",
   "metadata": {},
   "source": [
    "### Espacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe465e-7f0c-4ee7-a1e3-19f71c903379",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_rev[sample_index][:9] == good_rev[sample_index][:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d00b3-9982-4e88-b361-bb4d04b47739",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_rev[sample_index][10] == ' ' and good_rev[sample_index][10] == ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c51db5-b48a-4d16-af3d-40b208f3c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_rev[sample_index][-1] == good_rev[sample_index][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5586b-bba3-4b72-a6cb-98741894cb3f",
   "metadata": {},
   "source": [
    "### Hacer el masking con seeds diferentes y ver si cambia la cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32de55b-4eb2-4329-93f9-465de128f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "book_id_versions = create_word_split_sets(bib_sel_book_verses[ITALIAN_BIBLE], \n",
    "                                          N_MERGES, \n",
    "                                          OUTPUT_PATH, \n",
    "                                          ITALIAN_BIBLE)\n",
    "n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "verse_tokens = n_pairs_verses[0]\n",
    "filename = os.path.join(BIBLES_PATH, ITALIAN_BIBLE)\n",
    "base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{ITALIAN_BOOK_ID}_v{0}')\n",
    "entropies = get_entropies(verse_tokens,\n",
    "                                                       base_filename,\n",
    "                                                       REMOVE_MISMATCHER_FILES,\n",
    "                                                       char_counter,\n",
    "                                                       MISMATCHER_PATH)\n",
    "print('before:', entropies)\n",
    "random.seed(30)\n",
    "entropies = get_entropies(verse_tokens,\n",
    "                                                       base_filename,\n",
    "                                                       REMOVE_MISMATCHER_FILES,\n",
    "                                                       char_counter,\n",
    "                                                       MISMATCHER_PATH)\n",
    "print('after:', entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e19109-5189-46cb-a786-dba2fb246ab1",
   "metadata": {},
   "source": [
    "It's not the random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073defa-c02d-46fe-84eb-04b135570710",
   "metadata": {},
   "source": [
    "### Indices de los versículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525fbc0-2d9d-47b4-9470-5bd41de888a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_indices = [el[:8] for el in bad_rev]\n",
    "good_indices = [el[:8] for el in good_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f7523-0230-451b-87c5-8ba08d6992fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_indices == good_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b8a2c-e755-47f0-b966-7edf8de65c1f",
   "metadata": {},
   "source": [
    "The indices are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd187c9-61eb-4522-b610-1707db86d856",
   "metadata": {},
   "source": [
    "### Repeticion de texto\n",
    "\n",
    "- several indices are empty, while the preceeding verses are longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120a8a3-37e3-4c64-89be-96f5aaf3bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[el for el in bad_rev if el[8:].strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364e9c1-94e5-476b-bc86-b55d9ed3d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[el for el in good_rev if el[8:].strip() == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afebf4-2232-43c6-b2aa-25ab41a1e4c7",
   "metadata": {},
   "source": [
    "Furthermore, verse 66007004 has repeated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40b64b-04b5-4b02-806a-c7a31ea321bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_verses = [int(el) for el in bad_rev if el[8:].strip() == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543a111-c47b-4dc5-bc95-0cf63bc50772",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_verses = [el - 1 for el in empty_verses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc2109-848d-4732-b81f-bccb0c34cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_verses = sorted(set(empty_verses + previous_verses))\n",
    "print('exclude', excluded_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9f022-d64f-46a4-adc4-313eff5cd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_entropies = {}\n",
    "for bib in df[df['bible'].apply(lambda x: x.startswith('ita'))]['bible'].unique():\n",
    "    filename = os.path.join(BIBLES_PATH, bib)\n",
    "    chosen_books = [ITALIAN_BOOK_ID]\n",
    "    # Read the complete bible\n",
    "    bible = data.parse_pbc_bible(filename)\n",
    "    # Tokenize by splitting on spaces\n",
    "    tokenized = bible.tokenize(remove_punctuation=False, lowercase=LOWERCASE)\n",
    "    book_verses = {k: v for k, v in tokenized.verse_tokens.items() if k.startswith(str(ITALIAN_BOOK_ID))}\n",
    "    selected_verses = {k: v for k, v in book_verses.items() if int(k) not in excluded_verses}\n",
    "    _, _, book_verses, _, _ = data.join_by_toc(selected_verses)\n",
    "    selected_book_verses = select_samples(book_verses, [ITALIAN_BOOK_ID], TRUNCATE_BOOKS)\n",
    "    char_counter = get_char_distribution(''.join([el for lis in selected_verses.values() \n",
    "                                                  for el in lis]))\n",
    "    book_id_versions = create_word_split_sets(selected_book_verses, N_MERGES, OUTPUT_PATH, \n",
    "                                              filename.split('/')[-1])\n",
    "    n_pairs_verses = book_id_versions[ITALIAN_BOOK_ID]\n",
    "    verse_tokens = n_pairs_verses[0]\n",
    "    base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "    base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{ITALIAN_BOOK_ID}_v{0}')\n",
    "    entropies = get_entropies(verse_tokens,\n",
    "                                                       base_filename,\n",
    "                                                       REMOVE_MISMATCHER_FILES,\n",
    "                                                       char_counter,\n",
    "                                                       MISMATCHER_PATH)\n",
    "    bible_entropies[bib] = entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5887ba8-ea2f-491f-93dd-76265b2f2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_entropies['ita-x-bible-riveduta.txt']['masked'] - bible_entropies['ita-x-bible-riveduta.txt']['orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde2b8b-8e03-48c8-8752-e2df281f0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_entropies[ITALIAN_BIBLE]['masked'] - bible_entropies[ITALIAN_BIBLE]['orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc19e2-d196-4e95-b86f-9a32449cb4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(previous_verses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58594581-ec9d-40b1-b916-c41a9d66d7f5",
   "metadata": {},
   "source": [
    "I created a version of the file that excludes the empty verses and their preceding verses, and now the results are consistent with the other Italian-language bibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ccd34-d5c3-4a39-9cb5-35c95325bfd7",
   "metadata": {},
   "source": [
    "### Commits más recientes en esta Biblia\n",
    "\n",
    "No hay. He abierto una \"issue\".\n",
    "\n",
    "## Más preguntas\n",
    "\n",
    "- Do general results hold without this bible?\n",
    "- What are the correlation values for this bible?\n",
    "- What does it cost me to remove this bible?\n",
    "- Do other bibles also contain empty lines?\n",
    "\n",
    "### Other bibles with empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7c96d-54da-47cb-a079-ca21b1df1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibles_with_empty_verses = []\n",
    "selected_books = [40, 41, 42, 43, 44, 66]\n",
    "bibles = os.listdir(BIBLES_PATH)\n",
    "for bible in bibles:\n",
    "    with open(os.path.join(BIBLES_PATH, bible)) as f:\n",
    "        lines = f.readlines()\n",
    "    verses = [line.strip() for line in lines if any([line.strip().startswith(str(book)) \n",
    "                                                     for book in selected_books])]\n",
    "    empty_verses = [verse for verse in verses if verse[8:].strip() == '']\n",
    "    if len(empty_verses) > 0:\n",
    "        bibles_with_empty_verses.append((bible, empty_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfb730-6bf9-4fd3-8ef0-d5c9423aed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bibles_with_empty_verses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09167a2a-bebf-4953-884b-5675df49dfe2",
   "metadata": {},
   "source": [
    "1441 bibles have empty verses. This means that empty verses are not the problem. \n",
    "\n",
    "### Long lines\n",
    "\n",
    "How long was the problematic verse in the bible we just looked at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb038b0-db03-4fae-84dd-cba7cc1e7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BIBLES_PATH, ITALIAN_BIBLE)) as f:\n",
    "    lines = f.readlines()\n",
    "verses = [line.strip() for line in lines if line.startswith(str(ITALIAN_BOOK_ID))]\n",
    "problem_verse = [verse for verse in verses if verse.startswith('66007004')]\n",
    "assert len(problem_verse) == 1\n",
    "problem_verse = problem_verse[0]\n",
    "print(len(problem_verse[9:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f6ee4-085a-446d-926e-26ef7d233502",
   "metadata": {},
   "source": [
    "So let's see how many bibles have at least one verse with half this length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad295ab-b218-42bb-a258-15c8d5dd8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibles_with_long_verses = []\n",
    "selected_books = [40, 41, 42, 43, 44, 66]\n",
    "bibles = os.listdir(BIBLES_PATH)\n",
    "for bible in bibles:\n",
    "    with open(os.path.join(BIBLES_PATH, bible)) as f:\n",
    "        lines = f.readlines()\n",
    "    verses = [line.strip() for line in lines if any([line.strip().startswith(str(book)) \n",
    "                                                     for book in selected_books])]\n",
    "    long_verses = [verse for verse in verses if len(verse[8:].strip()) > 1500]\n",
    "    if len(long_verses) > 0:\n",
    "        bibles_with_long_verses.append((bible, long_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21838317-7121-45d6-9210-e46e554f863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bibles_with_long_verses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2af99-1cf5-4738-963a-88d4ac977495",
   "metadata": {},
   "source": [
    "70 is around 3% of all the bibles. I can believe that this could be a problem. Let's take a random one and look at the word-order vs word-structure plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04ab9f-5bc9-4396-8315-920fbedc5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_w_long_verse = random.choice(bibles_with_long_verses)\n",
    "print(bib_w_long_verse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c81037-a394-4359-9d4a-4c21f820f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_book_plot(df[df['bible'] == bib_w_long_verse[0]], \n",
    "               BOOK_ID_NAME[bib_w_long_verse[1][0][:2]], \n",
    "               bib_w_long_verse[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ffff5-d0a5-4641-928c-c8896bca3815",
   "metadata": {},
   "source": [
    "This did not give 0 values in the way we saw for the Italian bible. So, the final suspicion is that this is because of repeated text. What is the longest text sequence that repeats at least 1 in the Italian bible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6746a-7f30-44cd-8126-0d2bb7321cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_longest_repeating_seq(text: str) -> int:\n",
    "    candidate = (0, -1)\n",
    "    for n in range(1, int(len(text) / 2)):\n",
    "        for ix in range(len(text)):\n",
    "            if text[ix:ix+n] in text[ix+n:]:\n",
    "                candidate = (n, ix)\n",
    "                break\n",
    "        if candidate[0] < n:\n",
    "            break\n",
    "    return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2a5ee-e7d2-4c44-a250-e6f46d414910",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'aaaaabaaaaaaBible ita-x-bible-vita1997.txt contains several empty verses, because their content seems merged with a preceding verse. More importantly, verse 66007004 is especially suspicious, as it contains a lot of repeated text. This is not present in other Italian-language bibles, and I believe it is a transcription error. The metadata for this translation points to https://www.bible.com/bible/92/mat.1.bdg, which no longer works. None of the versions found in https://www.bible.com/bible/92 corresponds to either La Parola è Vita or 1997. The publisher is listed as \"Biblica, Inc.\", but https://www.biblica.com does not work.'\n",
    "get_len_longest_repeating_seq(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6d894-643b-45d4-a5f6-d54dcf825936",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BIBLES_PATH, ITALIAN_BIBLE)) as f:\n",
    "    lines = [el[8:].strip() for el in f.readlines() if el.startswith('66007004')]\n",
    "assert len(lines) == 1\n",
    "line = lines[0]\n",
    "print(get_len_longest_repeating_seq(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1308c8f-bdbd-4964-897d-3d9a7efd262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(line[:1162])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37cf9c-9adc-42d5-8695-dd0924673077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(line[1162:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f438af1-1820-4a37-a06d-e82878b5d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bible, long_verses in bibles_with_long_verses:\n",
    "    for long_verse in long_verses:\n",
    "        verse = long_verse[8:].strip()\n",
    "        if get_len_longest_repeating_seq(verse)[0] > 600:\n",
    "            print(bible, long_verse[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde55430-d8e6-4bd6-a8d8-d58299cf3f6e",
   "metadata": {},
   "source": [
    "So, the only other bible with such long verse with repeating text is kss-x-bible.txt. Let's look at the plot for that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e693a-81ed-4ed3-ab6a-b071f8f94f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_book_plot(df[df['bible'] == 'kss-x-bible.txt'], \n",
    "               BOOK_ID_NAME['40'], \n",
    "               'kss-x-bible.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd93b0-159a-4c8e-b6e1-9aacbd3c9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_book_plot(df[df['bible'] == 'kss-x-bible.txt'], \n",
    "               BOOK_ID_NAME['41'], \n",
    "               'kss-x-bible.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52b7d5-d722-493d-b650-17c2559eaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_book_plot(df[df['bible'] == 'kss-x-bible.txt'], \n",
    "               BOOK_ID_NAME['42'], \n",
    "               'kss-x-bible.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263d816-da9c-44a8-aa21-b8373031e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_book_plot(df[df['bible'] == 'kss-x-bible.txt'], \n",
    "               BOOK_ID_NAME['44'], \n",
    "               'kss-x-bible.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940c718-4fb1-41ca-b047-b8f6f577e77b",
   "metadata": {},
   "source": [
    "### Do general results hold without this bible?\n",
    "\n",
    "It seems so, because the general trends are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e2659-f43c-48f8-a25f-2ae779e8b7b0",
   "metadata": {},
   "source": [
    "### What are the correlation values for this bible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e014e-9d84-4d5f-94f4-a849d7b52705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_splits'] = df.apply(lambda row: row['iter_id'] if row['experiment'] == 'splitting' \n",
    "                          else (-1) * row['iter_id'], 1)\n",
    "get_spearman(df[(df['bible'] == ITALIAN_BIBLE) & (df['book'] == ITALIAN_BOOK)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c8e29-b255-4773-9d8e-2a64c7e7781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Italian bible\n",
    "other_ita_bib = df[(df['bible'].apply(lambda x: x.startswith('ita') and x != ITALIAN_BIBLE))].bible.tolist()[0]\n",
    "get_spearman(df[(df['bible'] == other_ita_bib) & (df['book'] == ITALIAN_BOOK)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f0e87-427e-4d07-aeca-d7532d8c1f44",
   "metadata": {},
   "source": [
    "The conclusions do not change significantly. What about the other bible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929266f-46dd-4dd2-967e-36756953d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_spearman(df[(df['bible'] == 'kss-x-bible.txt') & (df['book'] == BOOK_ID_NAME['41'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a66882-f49f-4c7e-b449-3c4f54e227cd",
   "metadata": {},
   "source": [
    "Again, consistent with what we observe for all bibles, so I'm not worried. The functional form might change but the Spearman correlation coefficient does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8dd4d0-aaa9-4eb6-b9b5-59cdb6128ebf",
   "metadata": {},
   "source": [
    "### What does it cost me to remove this bible?\n",
    "\n",
    "If I add these two bibles to the list of bibles to be excluded, then modify notebook 34 and run it again, I should be able to update the results very quickly.\n",
    "\n",
    "I did this, and obtained the same results, so I will not change the plots on the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc29eda-5fc8-46f7-8a32-12576ac177c0",
   "metadata": {},
   "source": [
    "# etu-x-bible.txt, John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2a946-7fcf-4a37-bf66-ecd8409c490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bible'] == ETU_BIBLE) & (df['book'] == ETU_BOOK) & (df['iter_id'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4b65e-2a33-464d-a256-21c5f2992cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name_id = {v: int(k) for k, v in BOOK_ID_NAME.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9210f-f668-4606-856d-214c9efefe88",
   "metadata": {},
   "source": [
    "This is extremely suspicious: why should the shuffled and masked versions have rather significantly different values, while the 'orig' values are entirely the same? The shuffling and masking is done in entirely the same way by the two get_entropies functions, and they call the same get_entropy function. My preferred explanation: this book is too short, so that random fluctuations matter. Let's run the function a few times with different seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939c843-c53a-4b9f-9e64-70943a33f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(seed):\n",
    "    random.seed(seed)\n",
    "    filename = os.path.join(BIBLES_PATH, ETU_BIBLE)\n",
    "    book_id = book_name_id[ETU_BOOK]\n",
    "    selected_book_verses, char_counter = read_selected_verses(filename,\n",
    "                                                                  LOWERCASE,\n",
    "                                                                  [book_id],\n",
    "                                                                  TRUNCATE_BOOKS)\n",
    "    book_id_versions = create_word_split_sets(selected_book_verses, N_MERGES, OUTPUT_PATH, ETU_BIBLE)\n",
    "    n_pairs_verses = book_id_versions[book_name_id[ETU_BOOK]]\n",
    "    sample_verses = n_pairs_verses[0]\n",
    "    base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "    base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{book_id}_v{0}')\n",
    "    entropies = get_entropies(sample_verses,\n",
    "                      base_filename,\n",
    "                      REMOVE_MISMATCHER_FILES,\n",
    "                      char_counter,\n",
    "                      MISMATCHER_PATH)\n",
    "    return entropies\n",
    "\n",
    "entropies_experiments = []\n",
    "for seed in (10, 30, 100, 300, 1000):\n",
    "    entropies_experiments.append(run_experiment(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f29aa-fce6-4e3f-98ed-6195f81c4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ('orig', 'shuffled', 'masked'):\n",
    "    print(k, [el[k] for el in entropies_experiments])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dfc63-cf9d-4713-a615-39a98c57d93a",
   "metadata": {},
   "source": [
    "The results were completely consistent from one run to the next, so that cannot be the explanation. Let's try to use the compression_entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f8408-90ad-46ed-985f-1dacbebc68f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(BIBLES_PATH, ETU_BIBLE)\n",
    "book_id = book_name_id[ETU_BOOK]\n",
    "selected_book_verses, char_counter = read_selected_verses(filename,\n",
    "                                                              LOWERCASE,\n",
    "                                                              [book_id],\n",
    "                                                              TRUNCATE_BOOKS)\n",
    "book_id_versions = create_word_split_sets(selected_book_verses, N_MERGES, OUTPUT_PATH, ETU_BIBLE)\n",
    "n_pairs_verses = book_id_versions[book_name_id[ETU_BOOK]]\n",
    "sample_verses = n_pairs_verses[0]\n",
    "base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{book_id}_v{0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ddf059-b202-4d6f-9a4f-d9a22a45a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_verse_tokens = [[token.token for token in verse] for verse in sample_verses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711f7bf-6821-4b7b-8e0c-91cd6f3a6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_pasting_entropies(sample_verse_tokens,\n",
    "                  base_filename,\n",
    "                  REMOVE_MISMATCHER_FILES,\n",
    "                  char_counter,\n",
    "                  MISMATCHER_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf355ad-62ca-4b77-bf79-af92f46116fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bible'] == ETU_BIBLE) & (df['book'] == ETU_BOOK) & (df['experiment'] == 'pasting') & (df['iter_id'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe2daa-728d-410f-bcce-f6f99f036a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bible'] == ETU_BIBLE) & (df['book'] == ETU_BOOK) & (df['experiment'] == 'splitting') & (df['iter_id'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54aa8c8-3a8f-469b-9b97-a24d9246e415",
   "metadata": {},
   "source": [
    "Now, interestingly, the values I got were different from both the splitting and pasting values obtained before. Is it the case that, in the case of pasting, the random seed matters more? It seems odd, but let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d21362-a3ba-4ae1-a4ab-0c9d1381e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pasting_experiment(seed):\n",
    "    random.seed(seed)\n",
    "    filename = os.path.join(BIBLES_PATH, ETU_BIBLE)\n",
    "    book_id = book_name_id[ETU_BOOK]\n",
    "    selected_book_verses, char_counter = read_selected_verses(filename,\n",
    "                                                                  LOWERCASE,\n",
    "                                                                  [book_id],\n",
    "                                                                  TRUNCATE_BOOKS)\n",
    "    book_id_versions = create_word_split_sets(selected_book_verses, N_MERGES, OUTPUT_PATH, ETU_BIBLE)\n",
    "    n_pairs_verses = book_id_versions[book_name_id[ETU_BOOK]]\n",
    "    sample_verses = n_pairs_verses[0]\n",
    "    base_dir = get_output_file_dir(OUTPUT_PATH, filename)\n",
    "    base_filename = os.path.join(base_dir, f'{os.path.basename(filename)}_{book_id}_v{0}')\n",
    "    sample_verse_tokens = [[token.token for token in verse] for verse in sample_verses]\n",
    "    entropies = get_pasting_entropies(sample_verse_tokens,\n",
    "                  base_filename,\n",
    "                  REMOVE_MISMATCHER_FILES,\n",
    "                  char_counter,\n",
    "                  MISMATCHER_PATH)\n",
    "    return entropies\n",
    "\n",
    "entropies_experiments = []\n",
    "for seed in (10, 30, 100, 300, 1000):\n",
    "    entropies_experiments.append(run_pasting_experiment(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65df1c-5c3a-4ebf-a3af-f42960f7b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ('orig', 'shuffled', 'masked'):\n",
    "    print(k, [el[k] for el in entropies_experiments])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8c9b2-6abc-4e26-95af-859d87a949e7",
   "metadata": {},
   "source": [
    "These are also self-consistent. What if this bible contains a start-of-token character that matches the one I reserved for middle-of-token starting character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc3348-73c6-42fc-9480-e0c9e77b042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_tokens = random.sample(sample_verses, k=len(sample_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8055999-fb9a-4b38-a59f-3d9d764787ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = [random.sample(words, k=len(words)) for words in verse_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fe16b-ba3d-439d-bf69-1ac83d1ed5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_str = ''.join(char_counter.keys())\n",
    "char_weights = [char_counter[el] for el in char_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012fab4-8eb0-4f30-8211-20ff3fc939d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compression_entropy import join_verses as join_verses_pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a110e-8ddf-48ae-9fbd-570558c682b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_splitting = join_verses(shuffled, insert_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90901a06-0a11-4a93-a03b-1eebf27ec730",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pasting = join_verses_pasting([[token.token for token in verse] for verse in shuffled], insert_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cb8fd-449c-4947-9b3b-cde8bc57d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_splitting[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bd09d-ba51-4f2f-953f-2e8719792a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pasting[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d0fed-664d-403b-aebf-58639062a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[el for el in shuffled[0] if not el.is_start_of_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea5eda-1df4-40b6-8592-546ff2825358",
   "metadata": {},
   "source": [
    "I had to look through the code in debug mode, but eventually I found that the problem is that there are certain non-standard whitespaces in the bible, such as here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6abef3-a8b9-481f-9f2e-217ff9c9f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'a bhá'.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ff9e4-caef-483d-98ad-c9b7f6f7aef0",
   "metadata": {},
   "source": [
    "Not specifying the split character would have been better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef741e5-09a3-48ca-9f1f-09652bfaa0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'a bhá'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ae934-5d42-4c5f-93d8-56bb0fc736e0",
   "metadata": {},
   "source": [
    "Action points:\n",
    "\n",
    "1. Add an issue on Github\n",
    "2. Add a todo in my code\n",
    "3. Verify if many bibles have this issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d906aa2-2f82-4089-a072-601eb2ef98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bible in os.listdir(BIBLES_PATH):\n",
    "    if bible in skip_bibles:\n",
    "        continue\n",
    "    with open(os.path.join(BIBLES_PATH, bible)) as f:\n",
    "        lines = f.readlines()\n",
    "    reached_notes = False\n",
    "    found_weird = False\n",
    "    for line in lines:\n",
    "        if '# notes' in line.lower():\n",
    "            reached_notes = True\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        if not reached_notes:\n",
    "            continue\n",
    "        try:\n",
    "            if int(line[:2]) not in selected_books:\n",
    "                continue\n",
    "        except ValueError as e:\n",
    "            print('ERROR:', bible, line)\n",
    "            raise e\n",
    "        content = line[8:].strip()\n",
    "        if content.split() != content.split(' ') and content.strip() != '':\n",
    "            print(bible, line[:8].strip())\n",
    "            found_weird = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61048f86-3e9b-4e09-815b-4ed2d0b3d6b6",
   "metadata": {},
   "source": [
    "I'm not going to exclude these in the final analysis, but I tried excluding them as a check, and nothing changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a58cf-66e9-488f-8927-e0ada938cc63",
   "metadata": {},
   "source": [
    "# all bibles that have relatively large gaps at the 0-points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b93499-65e0-4786-800b-33f14303744f",
   "metadata": {},
   "source": [
    "After all the checks above, all remaining differences are insignificant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
