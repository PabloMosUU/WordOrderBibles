{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress, spearmanr\n",
    "import numpy as np\n",
    "from data import build_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bible_name(filename: str) -> tuple:\n",
    "    parts = filename.replace('.txt\\n', '').split('-')\n",
    "    language = parts[0]\n",
    "    assert parts[1] == 'x'\n",
    "    assert parts[2] == 'bible', (filename, parts[2])\n",
    "    description = '-'.join(parts[3:])\n",
    "    return f'{language}-{description}' if description else language\n",
    "    return (language, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies_most = build_dataframe('output/KoplenigEtAl/entropies_backup.json')\n",
    "entropies_zho = build_dataframe('output/KoplenigEtAl/entropies_zho.json')\n",
    "df = pd.concat([entropies_most, entropies_zho])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['filename'].apply(lambda x: x.split('-')[0])\n",
    "df['description'] = df['filename'].apply(lambda x: '-'.join(x.split('.')[0].split('-')[3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename general Chinese as Mandarin Chinese to match Koplenig et al\n",
    "df['language'] = df['language'].apply(lambda x: 'cmn' if x == 'zho' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Burmese, as Koplenig et al don't explain how they inserted spaces\n",
    "df = df[df['language'] != 'mya'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D_structure'] = df.apply(lambda row: row['masked'] - row['orig'], 1)\n",
    "df['D_order'] = df.apply(lambda row: row['shuffled'] - row['orig'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_id_name = {'40': 'Matthew', \n",
    "                '41': 'Mark', \n",
    "                '42': 'Luke', \n",
    "                '43': 'John', \n",
    "                '44': 'Acts', \n",
    "                '66': 'Revelation'}\n",
    "df['book'] = df['book_id'].map(book_id_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bible_id'] = df['filename'].apply(parse_bible_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_name in df['book'].unique():\n",
    "    book_df = df[df['book'] == book_name]\n",
    "    assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "    x = book_df['D_order'].tolist()\n",
    "    y = book_df['D_structure'].tolist()\n",
    "    labels = book_df['bible_id'].tolist()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y)\n",
    "    plt.xlabel('Word order information')\n",
    "    plt.ylabel('Word structure information')\n",
    "    plt.title(book_name)\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.annotate(txt, (x[i], y[i]), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = 'John'\n",
    "book_df = df[df['book'] == book_name]\n",
    "assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "\n",
    "book_df = book_df[['language', 'D_order', 'D_structure']].groupby('language').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = book_df['D_order'].tolist()\n",
    "y = book_df['D_structure'].tolist()\n",
    "labels = book_df['language'].tolist()\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "plt.xlabel('Word order information')\n",
    "plt.ylabel('Word structure information')\n",
    "plt.title(book_name)\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (x[i], y[i]), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify:\n",
    "\n",
    "* trade-off cualitativo\n",
    "* valor del fit\n",
    "* rank correlation coefficient entre los ordenes de los idiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade-off cualitativo\n",
    "\n",
    "Si grafico estos idiomas para los 6 libros, me da un patron similar al que se ve en Koplenig et al?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_name in sorted(df['book'].unique()):\n",
    "    book_df = df[df['book'] == book_name]\n",
    "    assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "    book_df = book_df[['language', 'D_order', 'D_structure']].groupby('language').mean().reset_index()\n",
    "    x = book_df['D_order'].tolist()\n",
    "    y = book_df['D_structure'].tolist()\n",
    "    labels = book_df['language'].tolist()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y)\n",
    "    plt.xlabel('Word order information')\n",
    "    plt.ylabel('Word structure information')\n",
    "    plt.title(book_name)\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.annotate(txt, (x[i], y[i]), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, this is the same as in Koplenig et al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valor del fit\n",
    "\n",
    "Podemos hacer un fit como hicieron en Koplenig et al, y ver si da parecido. Caveat: ellos usaron todos los idiomas, y yo estoy usando solo los que resaltaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_inverse(xi, A, B):\n",
    "    return A * B / xi\n",
    "\n",
    "for book_name in sorted(df['book'].unique()):\n",
    "    book_df = df[df['book'] == book_name]\n",
    "    assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "    book_df = book_df[['language', 'D_order', 'D_structure']].groupby('language').mean().reset_index()\n",
    "    book_df.sort_values('D_order', ascending=True, inplace=True)\n",
    "    x = book_df['D_order'].tolist()\n",
    "    y = book_df['D_structure'].tolist()\n",
    "    labels = book_df['language'].tolist()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x, y)\n",
    "    plt.xlabel('Word order information')\n",
    "    plt.ylabel('Word structure information')\n",
    "    plt.title(book_name)\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.annotate(txt, (x[i], y[i]), rotation=45)\n",
    "    inv_x = [1 / el for el in x]\n",
    "    inv_x.reverse()\n",
    "    rev_y = y.copy()\n",
    "    rev_y.reverse()\n",
    "    inv_x = np.array(inv_x)\n",
    "    rev_y = np.array(rev_y)\n",
    "    res = linregress(inv_x, rev_y)\n",
    "    pred_y = [el for el in res.intercept + res.slope* inv_x]\n",
    "    pred_y.reverse()\n",
    "    print(f\"{book_name}: R-squared: {res.rvalue**2:.2f}, intercept: {res.intercept:.2f}, slope: {res.slope:.2f}\")\n",
    "    plt.plot(x, pred_y, 'r', label='fitted line')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, these are similar to the results found in Koplenig et al. But they also computed the Spearman correlation coefficients for each book, and I didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_inverse(xi, A, B):\n",
    "    return A * B / xi\n",
    "\n",
    "for book_name in sorted(df['book'].unique()):\n",
    "    book_df = df[df['book'] == book_name]\n",
    "    assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "    book_df = book_df[['language', 'D_order', 'D_structure']].groupby('language').mean().reset_index()\n",
    "    book_df.sort_values('D_order', ascending=True, inplace=True)\n",
    "    x = book_df['D_order'].tolist()\n",
    "    y = book_df['D_structure'].tolist()\n",
    "    print(f\"{book_name}: r_s: {spearmanr(x, y).correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all stronger than those found in Koplenig et al, but I'm using fewer bibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank correlation coefficient entre los ordenes de los idiomas\n",
    "\n",
    "Ahora quiero ver si el rank que encuentro yo se correlaciona con el que encuentran ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure is high-to-low (top-to-bottom), order is low-to-high (left-to-right)\n",
    "acts_structure = 'esk qvw tam zul chr grc deu eng vie mya xuo cmn'\n",
    "acts_order = 'esk chr qvw zul deu tam grc eng vie xuo cmn mya'\n",
    "john_structure = 'qvw esk tam zul chr grc deu eng vie mya xuo cmn'\n",
    "john_order = 'esk qvw chr zul tam deu eng grc vie mya xuo cmn'\n",
    "luke_structure = 'qvw esk tam zul chr grc deu eng vie mya xuo cmn'\n",
    "luke_order = 'esk qvw chr zul deu tam grc eng vie mya xuo cmn'\n",
    "revelation_structure = 'qvw esk tam zul chr grc deu eng vie mya cmn xuo'\n",
    "revelation_order = 'esk qvw chr tam zul deu grc eng vie mya cmn xuo'\n",
    "book_rank = {'acts': {}, 'john': {}, 'luke': {}, 'revelation': {}}\n",
    "book_rank['acts']['structure'] = acts_structure.split(' ')\n",
    "book_rank['acts']['order'] = acts_order.split(' ')\n",
    "book_rank['john']['structure'] = john_structure.split(' ')\n",
    "book_rank['john']['order'] = john_order.split(' ')\n",
    "book_rank['luke']['structure'] = luke_structure.split(' ')\n",
    "book_rank['luke']['order'] = luke_order.split(' ')\n",
    "book_rank['revelation']['structure'] = revelation_structure.split(' ')\n",
    "book_rank['revelation']['order'] = revelation_order.split(' ')\n",
    "koplenig_et_al_books = {'chr', 'cmn', 'deu', 'eng', 'esk', 'grc', 'mya', 'tam', \n",
    "                        'qvw', 'vie', 'xuo', 'zul'}\n",
    "for book in book_rank.keys():\n",
    "    for quantity in book_rank[book].keys():\n",
    "        assert set(book_rank[book][quantity]) == koplenig_et_al_books\n",
    "        assert len(book_rank[book][quantity]) == len(koplenig_et_al_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mya from the Koplenig et al results\n",
    "for book, rest in book_rank.items():\n",
    "    for q, v in rest.items():\n",
    "        v.remove('mya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_name in sorted(df['book'].unique()):\n",
    "    if book_name.lower() not in book_rank.keys():\n",
    "        continue\n",
    "    book_df = df[df['book'] == book_name]\n",
    "    assert len(book_df) == book_df['bible_id'].nunique(), book_name\n",
    "    book_df = book_df[['language', 'D_order', 'D_structure']].groupby('language').mean().reset_index()\n",
    "    x_pm = book_df['D_order'].tolist()\n",
    "    y_pm = book_df['D_structure'].tolist()\n",
    "    labels = book_df['language'].tolist()\n",
    "    x_k = [book_rank[book_name.lower()]['order'].index(el) for el in labels]\n",
    "    y_k = [book_rank[book_name.lower()]['structure'].index(el) for el in labels]\n",
    "    print(f\"{book_name}: r_s: {spearmanr(x_pm, x_k).correlation:.2f}\")\n",
    "    print(f\"{book_name}: r_s: {spearmanr(y_pm, y_k).correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my findings correlate very strongly with those of Koplenig et al, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
