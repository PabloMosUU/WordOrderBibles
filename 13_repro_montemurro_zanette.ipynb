{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_FILES = 'output/MontemurroZanette/'\n",
    "LANGUAGE_MAP = {'deu': 'German', 'vie': 'Vietnamese', 'eng': 'English', 'mya': 'Burmese', \n",
    "                'esk': 'Inupiatun', 'zho': 'Chinese', 'grc': 'Greek', 'tam': 'Tamil', \n",
    "                'zul': 'Zulu', 'qvw': 'Quechua', 'chr': 'Cherokee', 'xuo': 'Kuo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(MZ_FILES)\n",
    "entropy_files = [el for el in all_files if 'entropies' in el]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([el.endswith('_entropies.csv') for el in entropy_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [(filename, pd.read_csv(MZ_FILES + filename)) for filename in entropy_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataframes)):\n",
    "    dataframes[i][1]['filename'] = dataframes[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [el[1] for el in dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df['iso'] = df['filename'].apply(lambda x: x.split('-')[0])\n",
    "    df['bible_id'] = df['filename'].apply(lambda x: x.replace('_entropies.csv', '')[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df.drop(columns=['filename'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df['temp'] = df.apply(lambda row: row['H_r'] - row['H'], 1)\n",
    "    df['temp2'] = df.apply(lambda row: abs(row['temp'] - row['D_r']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    assert all([el < 0.001 for el in df['temp2'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df.drop(columns=['temp', 'temp2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['iso'].map(LANGUAGE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_entropies(the_level: str, the_unigram: str) -> None:\n",
    "    level_df = df[df['level'] == the_level].reset_index()\n",
    "    H_u = f'H_{the_unigram}'\n",
    "    D_u = f'D_{the_unigram}'\n",
    "    aggregators = {col: ['mean', 'std'] for col in ('H', H_u, D_u)}\n",
    "    results_df = level_df.groupby('language').agg(aggregators).reset_index().fillna(0)\n",
    "\n",
    "    X = results_df['language'].tolist()\n",
    "    X_axis = np.arange(len(X))\n",
    "    H_mean = results_df[('H', 'mean')].tolist()\n",
    "    H_u_mean = results_df[(H_u, 'mean')].tolist()\n",
    "    D_u_mean = results_df[(D_u, 'mean')].tolist()\n",
    "    H_std = results_df[('H', 'std')].tolist()\n",
    "    H_u_std = results_df[(H_u, 'std')].tolist()\n",
    "    D_u_std = results_df[(D_u, 'std')].tolist()\n",
    "\n",
    "    plt.figure(figsize=(16, 6), dpi=80)\n",
    "\n",
    "    plt.bar(X_axis - 0.3, H_u_mean, 0.3, color='blue', yerr=H_u_std, capsize=5)\n",
    "    plt.bar(X_axis, H_mean, 0.3, color='green', yerr=H_std, capsize=5)\n",
    "    plt.bar(X_axis + 0.3, D_u_mean, 0.3, color='red', yerr=D_u_std, capsize=5)\n",
    "\n",
    "    plt.xticks(X_axis, X)\n",
    "\n",
    "    plt.ylabel(\"entropy [bits/word]\")\n",
    "    plt.title(f\"Level: {the_level}. Unigram: {the_unigram}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in ('bible', 'book'):\n",
    "    for unigram in ('r', 's'):\n",
    "        plot_entropies(level, unigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "\n",
    "* the variance in the book-level analysis is too large, so we need to stick to bible-level analyses\n",
    "* the error bars then represent the variance among bibles in the same language, which are expected to be small\n",
    "* this is markedly not the case for Greek. There were some lowercased bibles there, and this might cause the difference\n",
    "* the results for 'r' and 's' are very similar and we can just stick to one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_level = 'bible'\n",
    "the_unigram = 'r'\n",
    "level_df = df[df['level'] == the_level].reset_index()\n",
    "H_u = f'H_{the_unigram}'\n",
    "D_u = f'D_{the_unigram}'\n",
    "aggregators = {col: ['mean', 'std'] for col in ('H', H_u, D_u)}\n",
    "results_df = level_df.groupby('language').agg(aggregators).reset_index().fillna(0)\n",
    "\n",
    "X = results_df['language'].tolist()\n",
    "X_axis = np.arange(len(X))\n",
    "H_mean = results_df[('H', 'mean')].tolist()\n",
    "H_u_mean = results_df[(H_u, 'mean')].tolist()\n",
    "D_u_mean = results_df[(D_u, 'mean')].tolist()\n",
    "H_std = results_df[('H', 'std')].tolist()\n",
    "H_u_std = results_df[(H_u, 'std')].tolist()\n",
    "D_u_std = results_df[(D_u, 'std')].tolist()\n",
    "\n",
    "print(f'Mean H: {np.mean(H_mean):.2f}; stdev(H_mean): {np.std(H_mean):.2f}')\n",
    "print(f'mean(H_r_mean): {np.mean(H_u_mean):.2f}. stdev(H_r_mean): {np.std(H_u_mean):.2f}')\n",
    "print(f'mean(D_r_mean): {np.mean(D_u_mean):.2f}. stdev(D_r_mean): {np.std(D_u_mean):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring standard deviations for each language, we can see that the variance in the mean value of the entropies (original and shuffled) are larger than the variance in the difference between the two entropies. This is exactly as reported in Montemurro & Zanette. However, the mean value of the mean difference between the original and shuffled entropies is 4.6 bits per word, over 1 bit per word higher than that reported by Montemurro & Zanette. This seems to suggest that, in my study, there is MORE information contained in word order than in the study of Montemurro & Zanette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Montemurro & Zanette also obtained basically the same result as Bentz et al (2017), who in Figure 1 show a narrow distribution of entropy differences with a mean value of 3.17 and a standard deviation of 0.36. My mean value lies 4 standard deviations away from theirs.\n",
    "\n",
    "Looking at the top plot in Figure 1 of Bentz et al, it looks like it is the mean UNIGRAM entropy that is significantly different from their result. We could try to use exactly the same method that they used, to see if we can reproduce that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
