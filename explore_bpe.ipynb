{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from word_splitting import create_word_split_sets\n",
    "import compression_entropy as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "tokenizer = Tokenizer(BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_file_no_verse_numbers = \"/home/pablo/Documents/GitHubRepos/paralleltext/bibles/corpus/eng-x-bible-world.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=[bible_file_no_verse_numbers], \n",
    "                trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"Hello, y'all! How are you üòÅ ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_verse = tokenizer.encode(\"The book of the generation of Jesus Christ , the son of David , the son of Abraham .\")\n",
    "print(first_verse.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = \"\"\n",
    "with open(bible_file_no_verse_numbers) as f:\n",
    "    full_text = f.readlines()\n",
    "    full_text = \" \".join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(full_text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = len(set(full_text.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], \n",
    "                     vocab_size=int(n_unique_words/6))\n",
    "tokenizer.train(files=[bible_file_no_verse_numbers], trainer=trainer)\n",
    "try:\n",
    "    output = tokenizer.encode(\"Hello, y'all! How are you üòÅ ?\")\n",
    "    print(output.tokens)\n",
    "    first_verse = tokenizer.encode(\"The book of the generation of Jesus Christ , the son of David , the son of Abraham .\")\n",
    "    print(first_verse.tokens)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_trainer(vocab_size: int):\n",
    "    return BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=vocab_size)\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "lowercased_text = full_text.lower()\n",
    "n_unique_lowercased_words = len(set(lowercased_text.split(' ')))\n",
    "trainer = start_trainer(int(n_unique_lowercased_words/2))\n",
    "with open('lowercased_text.txt', 'w') as f:\n",
    "    f.write(lowercased_text)\n",
    "tokenizer.train(files=['lowercased_text.txt'], trainer=trainer)\n",
    "output = tokenizer.encode(lowercased_text[:300])\n",
    "print(output.tokens)\n",
    "os.remove('lowercased_text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "tokenizers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyCharm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_save = {-2000, -1000, -300, -100, -30, 0, 30, 100, 300, 1000, 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/pablo/Documents/GitHubRepos/paralleltext/bibles/corpus/eng-x-bible-world.txt\"\n",
    "book_verses, char_counter = ce.read_selected_verses(filename, \n",
    "                                                    lowercase=True, \n",
    "                                                    chosen_books=[40], \n",
    "                                                    truncate_books=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_versions = create_word_split_sets(book_verses, steps_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{version: ' '.join(book_versions[40][version][0]) for version in sorted(book_versions[40].keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{version: len(set([el for lis in book_versions[40][version] for el in lis])) \\\n",
    " for version in sorted(book_versions[40].keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w in set([el for lis in book_versions[40][-1000] for el in lis]) \\\n",
    " if w not in set([el for lis in book_versions[40][0] for el in lis])][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' '.join(verse) for verse in book_versions[40][-1000] if 'sed' in verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[' '.join(verse) for verse in book_versions[40][-1000] if 'gethse' in verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w in set([el for lis in book_versions[40][-1000] for el in lis]) \\\n",
    " if w not in set([el for lis in book_versions[40][-2000] for el in lis])][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i, verse in enumerate(book_versions[40][-1000]) if 'gethse' in verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(book_versions[40][-2000][945])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word_order_bibles",
   "language": "python",
   "name": "word_order_bibles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
