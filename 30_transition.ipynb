{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad2144-6b51-4185-b450-90f06b093ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecc158-48aa-4668-8d64-49a64e6ae4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wp = pd.read_csv(\"../WordOrderBibles_HPC/output/KoplenigEtAl/WordPasting/entropies_aso-x-bible.txt.csv\")\n",
    "df_ws = pd.read_csv(\"output/KoplenigEtAl/WordSplitting/entropies_aso-x-bible.txt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965b2e5-0a8c-4a68-b2d6-57328f7c6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_wp = df_wp[df_wp['book_id'] == 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14167275-4431-48b3-9716-60fca6a26eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_ws = df_ws[df_ws['book_id'] == 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5b73b-1659-499c-8adc-3ed4a4f252a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(acts_wp), len(acts_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28084e47-d5d9-42c8-87fb-b373c1cdec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_wp[acts_wp['iter_id'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680f01f-97d3-4699-b96d-58d9b74a4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_ws[acts_ws['iter_id'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05da36b-adc1-4636-96f7-3f1f6fd2c396",
   "metadata": {},
   "source": [
    "I see two possible causes for this:\n",
    "\n",
    "1. the randomization significantly affects the results\n",
    "2. the tokenization changes slightly and this leads to discrepancies\n",
    "\n",
    "I'm inclined for option 1, because the \"orig\" entropy is virtually the same in both cases. I will test this by running the randomization procedure multiple times on the same version of the bible, i.e., without pasting or splitting, and seeing how the other quantities vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e009ad-4ce1-4c22-b84a-4fab95368572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import word_splitting as ws\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf055b-11c6-4e48-b9c2-caeaf3f9b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_book_verses, char_counter = ws.read_selected_verses(\"../paralleltext/bibles/corpus/aso-x-bible.txt\",\n",
    "                         True,\n",
    "                         [44],\n",
    "                         False)\n",
    "selected_acts_verses = selected_book_verses[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6c4c1-1743-4e3c-98cb-6bda37a73bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [[util.Token(token, True) for token in lis] for lis in selected_acts_verses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30119230-88bb-4892-a53f-6fbf6d5a0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = []\n",
    "for i in range(100):\n",
    "    entropies.append(ws.get_entropies(tokenized,\n",
    "                      'test_random_effects.out',\n",
    "                      True,\n",
    "                      char_counter,\n",
    "                      '../KoplenigEtAl/shortestmismatcher.jar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dbf6a-cc7b-4329-84a6-d92d53533c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58d5d9-ef90-42a1-b698-d06aef47976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d28b1-9957-46d3-8f2c-7d2d41849731",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ('orig', 'shuffled', 'masked'):\n",
    "    print(name, np.mean([el[name] for el in entropies]), np.std([el[name] for el in entropies]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604df979-f61a-4b50-8c83-0c4883ae1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_wp[acts_wp['iter_id'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd5bb6-dec4-4f01-be77-0e673009b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_ws[acts_ws['iter_id'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484d327-5226-4286-b34d-55ac6690702a",
   "metadata": {},
   "source": [
    "The sample standard deviation in the randomization experiment is extremely small, to the point where I strongly suspect there is something else going on. I am trying to debug the code to see what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d330bc7-ef62-4132-8806-e9827ab2e555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
